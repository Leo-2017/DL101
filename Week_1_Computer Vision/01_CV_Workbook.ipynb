{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_CV_Workbook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unpackAI/DL101/blob/main/Week_1_Computer%20Vision/01_CV_Workbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j04QL-TPJy1"
      },
      "source": [
        "# ðŸ’»Week 1 Workbook of unpackAI \"DL101 Bootcamp\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0joGgV0POOt"
      },
      "source": [
        "## ðŸ“• Learning Objectives of the Week\n",
        "\n",
        "* Understand the fundamental process of building your own image classification project."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## ðŸ”— Install & Import Required Code Packages \n",
        "!pip install -Uqq fastbook\n",
        "!pip install -Uqq unpackai\n",
        "from unpackai.utils import clean_error_img\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8IaH3aS2zG_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='red'>IMPORTANT</font> \n",
        "\n",
        "***After you ran the code above, restart the runtime in order to avoid the erros. You can press: `Ctrl + M + .` on your keyboard (Smash all three keys together. After that re-run the cell and enjoy the rest of the learning***. "
      ],
      "metadata": {
        "id": "DUlGGYnqlQLe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx21fMyjgV1v"
      },
      "source": [
        "## unpackAI Assignment Section\n",
        "\n",
        " \n",
        "*   **Assignment 1**: Go through the multiple choice questions below and choose the correct answer. Discuss during the presentation session.\n",
        "*   **Assignment 2**: Build an entire single label classification model starting from defining your objective, gathering data to training your model and interpreting the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2frVl71OQJi"
      },
      "source": [
        "## Assigment 1: Go through the multiple choice questions below and choose the correct answer. Discuss during the presentation session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0DZFcq_gnX"
      },
      "source": [
        "1. What is overfitting?\n",
        "\n",
        "> A: Overfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high loss on both the training set and unseen data.\n",
        "\n",
        "> B: Overfitting happens when a model learns and memorizes the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This results in a further decreasing loss on the training set but an increasing loss on the validation set.\n",
        "\n",
        "> C: Overfitting is when the model is performing very well on the training, validation and test set and achieves a very low loss in all 3 data sets. This means that your model is ready to be used in practice.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrGS533pAUsp"
      },
      "source": [
        "2. What is a training, validation and test set?\n",
        "\n",
        "> A: The *training set* is the sample of data used to start fitting and training the model. The *test set* is the sample of data used to evaluate the trained models performance on new data while continuing to improve and tune the model's parameters. The *validation set* is the sample of data used to evaluate the final model without continuing to tune its parameters.\n",
        "\n",
        "> B: The *test set* is the sample of data used to start fitting and training the model. The *training set* is the sample of data used to evaluate the trained models performance on new data while continuing to improve and tune the model's parameters. The *validation set* is the sample of data used to evaluate the final model without continuing to tune its parameters.\n",
        "\n",
        "> C: The *training set* is the sample of data used to start fitting and training the model. The *validation set* is the sample of data used to evaluate the trained models performance on new data while continuing to improve and tune the model's parameters. The *test set* is the sample of data used to evaluate the final model without continuing to tune its parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY8bqKOUNrY7"
      },
      "source": [
        "3. Observe the `Learner` that you have encountered in the Coursebook. What are the key **metrics** to represent the model's performance? Name and explain them.\n",
        "\n",
        "> A: The key metrics are *epochs* and *time*. Both give us key insights how much memory the model requires and its performance.\n",
        "\n",
        "> B: The key metrics are *train_loss*, *valid_loss* and *error rate / accuray*. Each metric provides insights on the model's performance on the training set, validation set and test set.\n",
        "\n",
        "> C: The single most important metric is the *loss*. The loss is what tells the machine and human how the model performs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szA0RuiL_4rR"
      },
      "source": [
        "4. What is the difference between Classification and Regression in Machine Learning?\n",
        "\n",
        "> A: A *classification model* is one that attempts to predict a class, or category. That is, it's predicting from a number of discrete possibilities, such as \"dog\" or \"cat\". A *regression model* is one that attempts to predict one or more numeric quantities, such as a temperature or a location.\n",
        "\n",
        "> B: A *regression model* is one that attempts to predict a class, or category. That is, it's predicting from a number of discrete possibilities, such as \"dog\" or \"cat\". A *classification model* is one that attempts to predict one or more numeric quantities, such as a temperature or a location.\n",
        "\n",
        "> C: A *classification model* is one that attempts to utilize sorting algorithms that can allow it to learn time-dependent patterns across multiples models different from images and speech. A *regression model* is one that attempts to to predict the \"rating\" or \"preference\" a user would give to an item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gst5sKGGCPLF"
      },
      "source": [
        "5. What is transfer learning in Machine Learning?\n",
        "\n",
        "> A: Transfer learning is a machine learning technique where the parameters of a model are not updated through model training but simply replaced by the parameters of another pre-trained model.\n",
        "\n",
        "> B: Transfer learning is a technique where a machine learning engineer uses his expertise and techniques in another industry to a problem in an industry he does not have much experience in.\n",
        "\n",
        "> C: A: Transfer learning is a machine learning technique where a pre-trained model is re-purposed on a second related task. In practice this means that, we use an existing already-trained model and its trained \"intelligence\" to utilize it for our own use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUbu_n7fiITe"
      },
      "source": [
        "## Assignment 2: Build an entire single label classification model starting from defining your objective, gathering data to training your model and interpreting the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1PTaXRGQKxS"
      },
      "source": [
        "### Step One - Define a ML problem and propose a solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDEouac7xN1v"
      },
      "source": [
        "#### 1. Define the objective (what goal, metrics to measure success)\n",
        "**Your objective:**\n",
        "\n",
        "*Example objective: The goal is to build a model that is able to differentiate between grizzly bears, black bears and teddy bears with a minimum accuracy of 90%.*\n",
        "#### 2. Describe your dataset (what data, how many classes etc.)\n",
        "**Your dataset:**\n",
        "\n",
        "*Example dataset: The dataset consists of a total of 450 images seperated in 3 different classes that each have a set of 150 images. The three classes are: \"black\", \"grizzly\" and \"teddy\".*\n",
        "#### 3. Describe your model (what is the model supposed to do)\n",
        "**Your model:**\n",
        "\n",
        "*Example model: A 3-class, single-label classification model, which correctly classifies an image that it has never seen before in one of three classes named above.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5QZmieCYbZ2"
      },
      "source": [
        "### Step Two - Collect and construct your dataset\n",
        "\n",
        "In order to collect and design your own dataset we provide you with the scraping tool below.\n",
        "\n",
        "**DuckDuckGo Image Scraper** - Scrape and Collect images via a search engine from the web.\n",
        "\n",
        "In order to collect your images we will be utilizing **DuckDuckGo**. DuckDuckGo is an internet search engine that emphasizes protecting searchers' privacy and avoiding the filter bubble of personalized search results.\n",
        "\n",
        "The below is a slightly modified version of the notebook by [Jew Dockrill](https://joedockrill.github.io/jmd_imagescraper/). Many thanks to him for the notebook and the package he wrote."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-Q8JvcH1-wf"
      },
      "source": [
        "> Note: When using a Web Search Engine to download your pictures, there's no way to be sure exactly what images a search like this will find. The results can change over time. We've heard of at least one case of a community member who found some unpleasant pictures in their search results. You'll receive whatever images are found by the web search engine. If you're running this at work, or with kids, etc, then be cautious before you display the downloaded images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqbxbj-EuAB9"
      },
      "source": [
        "##### Install & import `DuckDuckGoImageScraper` specific packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYwHbopFG63A"
      },
      "source": [
        "!pip install -q jmd_imagescraper\n",
        "from jmd_imagescraper.imagecleaner import *\n",
        "from pathlib import Path\n",
        "from jmd_imagescraper.core import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zDjCg2IuDw2"
      },
      "source": [
        "##### Download images\n",
        "\n",
        "Below you can see an example, of what changes would be required to work with a teddy, grizzly and black bear dataset.\n",
        "\n",
        "```\n",
        "IMAGE_DIR = Path(\"/content/gdrive/MyDrive/images\")  # Comment: You can store in a different Google Drive Folder\n",
        "number_images_to_download = 50         \n",
        "\n",
        "duckduckgo_search(IMAGE_DIR, \"teddy\", \"teddy bear\", max_results=number_images_to_download)\n",
        "duckduckgo_search(IMAGE_DIR, \"grizzly\", \"grizzly bear\", max_results=number_images_to_download)\n",
        "duckduckgo_search(IMAGE_DIR, \"black\", \"black bear\", max_results=number_images_to_download)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQWW2GmajFiA"
      },
      "source": [
        "Now modify the code below for your own use case. You will have to:\n",
        "\n",
        "1. `path`: Define the `path` which will be the folder in which you will temporarily save the images. Once you disconnect, the images will be deleted.\n",
        "1. `number_images_to_download`: The number of images you download per defined class. This can go up to 477 at the time of writing.\n",
        "1. `duckduckgo_search`: You will have to define your **classes** (for example: teddy, grizzly, black) and your **search term** (for example: teddy bear, grizzly bear, black bear).\n",
        "\n",
        "> Note: When downloading the images please make sure to check your search terms ahead of running the script below. Go and search for yourself to define the best search terms.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eIC5EJPvOt4"
      },
      "source": [
        "path = Path().cwd()/\"images\"\n",
        "number_images_to_download = 50\n",
        "\n",
        "duckduckgo_search(path, \"apple\", \"apple in the basket\", max_results=number_images_to_download)\n",
        "duckduckgo_search(path, \"orange\", \"orange\", max_results=number_images_to_download)\n",
        "duckduckgo_search(path, \"pineapple\", \"pineapple\", max_results=number_images_to_download)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnGy2r0wJOx"
      },
      "source": [
        "##### Displaying the image cleaner\n",
        "\n",
        "Use this to get rid of unsuitable images without leaving your notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBxc-SjZwO72"
      },
      "source": [
        "display_image_cleaner(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUDiaEimaS0X"
      },
      "source": [
        "Some time especially in real life projects, erronous image is a frequently occuring thing, you can fix the problem by deleting all of our faulty images. \n",
        "\n",
        "**We leave it up to you to finish your own model using your own dataset!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4TbB4ChlLLq"
      },
      "source": [
        "clean_error_img(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjU6eRv-f-Qg"
      },
      "source": [
        "#### Your own data\n",
        "\n",
        "If you want to use your own personal data, you can upload your images using the file system on the right (see the image below).\n",
        "\n",
        "> Hint: Make sure to define your path so that it points to your main folder that contains your labeled folders with the images. A great way to do that is to use the *folder* icon on the left, to find the right folder, right click and *copy path*.\n",
        "\n",
        "\n",
        "```\n",
        "path = Path(\"insert path here\")\n",
        "```\n",
        "\n",
        "**However, considering your own time, we recommend you to use the DuckDuckGo Image Scraper above.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuur3OFzYd16"
      },
      "source": [
        "### Step Three - Data Transformation: Create your **DataLoaders** and utilize **Data Augmentation Methods** to improve your dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_VOdle0vPX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYOIkqBuZAm5"
      },
      "source": [
        "### Step Three - Train your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnzDFAZZZXCf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXFzPxONZGu1"
      },
      "source": [
        "### Step Four - Interpret the model and make predictions: Create a notebook app to upload and classify external images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwIxc-Pb93D9"
      },
      "source": [
        "> Hint: Utilize the *top losses* and *classification marix* methods seen in the coursebook to interpret your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDmQ23JmZWrn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}