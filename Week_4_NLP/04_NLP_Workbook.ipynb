{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_NLP_Workbook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unpackAI/DL101/blob/main/04_NLP_Workbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j04QL-TPJy1"
      },
      "source": [
        "# ðŸ’»Week 4 Workbook of unpackAI ```DL101 Bootcamp```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0joGgV0POOt"
      },
      "source": [
        "## ðŸ“• Learning Objectives of the Week\n",
        "\n",
        "* Understand the fundamental process of building your own language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJvIFM7zjGnj"
      },
      "source": [
        "## ðŸŽ¸ Libraries & Dependencies needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azcl-ikfOQJR",
        "outputId": "b8aa7c99-578d-4c92-bbbf-e219624484a2"
      },
      "source": [
        "!pip install -Uqq unpackai\n",
        "# !pip install -q git+https://github.com/unpackai/unpackai\n",
        "!pip install -Uqq transformers==4.10.2\n",
        "!pip install -q datasets transformers[sentencepiece]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73 kB 1.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95 kB 2.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 189 kB 8.7 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56 kB 2.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.8 MB 5.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 22.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 37.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 5.9 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 44.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312 kB 5.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243 kB 48.6 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133 kB 50.0 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 44.5 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 45.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 3.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 50.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 44.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynOZVJ0HfD2Q"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    pipeline,\n",
        "    set_seed,\n",
        "    Trainer,\n",
        "    TextDataset,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from unpackai.nlp import Textual, InterpEmbeddingsTokenizer\n",
        "from ipywidgets import interact\n",
        "import logging\n",
        "from fastai import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx21fMyjgV1v"
      },
      "source": [
        "## unpackAI Assignment Section\n",
        "\n",
        " \n",
        "*   **Assignment 1**: Go through the multiple choice questions below and choose the correct answer. Discuss your answers during the presentation session.\n",
        "*   **Assignment 2**: Build an entire language model starting from defining your objective, gathering data to training your model and interpreting the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2frVl71OQJi"
      },
      "source": [
        "## Assigment 1: Multiple choice questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrGS533pAUsp"
      },
      "source": [
        "1. What is a Language Model?\n",
        "\n",
        "> A: A model that can talk.\n",
        "\n",
        "> B: A model that is able to generate text by copying and pasting different sections of text that it was trained on.\n",
        "\n",
        "> C: A model that is able to predict the most likely next word in a sequence of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0DZFcq_gnX"
      },
      "source": [
        "2. What is Tokenization in NLP?\n",
        "\n",
        "> A: Tokenization is the process of turning sensitive data into nonsensitive data called \"tokens\" that can be used in a database or internal system without bringing it into scope.\n",
        "\n",
        "> B: Tokenization is a technique to split words, numbers, commas etc. into sub units to allow for further processing.\n",
        "\n",
        "> C: Tokenization is a technique split the text dataset into a tokenized validation or training dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY8bqKOUNrY7"
      },
      "source": [
        "3. What are word-embeddings?\n",
        "\n",
        "> A: Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
        "\n",
        "> B: Word embeddings score the meaningfulness of a word. The higher the value of the learned features within a word-embeddings the more meaningful & important it is within the text dataset.\n",
        "\n",
        "> C: A word embedding is a learned feature of a word. This feature describes every word with a number between 1 and -1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUbu_n7fiITe"
      },
      "source": [
        "## Assignment 2: Build an entire Language Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1PTaXRGQKxS"
      },
      "source": [
        "### Step One - Define a ML problem and propose a solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDEouac7xN1v"
      },
      "source": [
        "#### 1. Define the objective\n",
        "**Your objective:**\n",
        "#### 2. Describe your dataset\n",
        "**Your dataset:**\n",
        "#### 3. Describe your model\n",
        "**Your model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5QZmieCYbZ2"
      },
      "source": [
        "### Step Two - Collect and construct your dataset\n",
        "\n",
        "In order to collect and design your own dataset we provide you with the `Textual` scraping tool below. For that you have two options!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Uma7pnjrm5"
      },
      "source": [
        "**Option 1: Collect text from an URL.**\n",
        "\n",
        "Provide an URL to the textual tool and all the text will be collected. We recommend [Gutenberg Project](https://gutenberg.org/) as a source which is a collection of over 60,000 free eBooks. Simply click on a book that you like and the corresponding txt file (see image below).\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/p5tyklp58d3yosa/Screen%20Shot%202021-09-13%20at%2017.49.52.png?dl=1\" alt=\"wordembeddings\" width=\"500\"/>\n",
        "\n",
        "However, feel free to experiment with other datasets from other URL sources.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCWwVhIAjjBK"
      },
      "source": [
        "textual = Textual.from_url(\"https://gutenberg.org/files/6130/6130-0.txt\")\n",
        "textual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1iDa9dplr2h"
      },
      "source": [
        "**Option 2: Collect text from path.**\n",
        "\n",
        "In case you have a downloaded txt file, feel free to upload it to the Google Drive and enter the path in the bracket below. Make sure that the file format is txt (a type of file just like ppt or csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TzPtIt0jpZc"
      },
      "source": [
        "textual = Textual.from_path(\"./the_txt_file_you_uploaded.txt\")\n",
        "textual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYOIkqBuZAm5"
      },
      "source": [
        "### Step Three - Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3TG7_8mZJU"
      },
      "source": [
        "We skip the Data Transformation as the Tokenization and Numericalisation happens during the Model Training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnzDFAZZZXCf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXFzPxONZGu1"
      },
      "source": [
        "### Step Four - Interpret the model and generate text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDmQ23JmZWrn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}